{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5acec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src path: /ehome/xinyi/Xinyi_GNN_aorta/src\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time as time\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "current_file_path = os.getcwd()\n",
    "src_path = os.path.abspath(os.path.join(current_file_path, \"../src\"))\n",
    "print(f\"src path: {src_path}\")\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853f2946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv already exists, loading data...\n",
      "data load done.\n"
     ]
    }
   ],
   "source": [
    "from utils import aorta_3D_info, Normalizer_ts\n",
    "\n",
    "processed_path = '/ehome/xinyi/Xinyi_GNN_aorta/data/toy_single/raw'\n",
    "outputpath     = '/ehome/xinyi/Xinyi_GNN_aorta/data/toy_single'\n",
    "data_label = ['y', 'pos', \"stmdist\"]\n",
    "\n",
    "data_information = aorta_3D_info(path=processed_path, labels=data_label, output_path=outputpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8286ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data.dataset import Poisson_2d_Dataset\n",
    "# from data.data_utils import poisson_info\n",
    "\n",
    "# root = '/ehome/xinyi/Xinyi_GNN_aorta/data/toy_single'\n",
    "# data_label = ['temperature', 'source']\n",
    "# data_information = poisson_info(path=root+'/raw', labels=data_label, output_path=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44038484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pressure</th>\n",
       "      <td>3.398470</td>\n",
       "      <td>-7.650037</td>\n",
       "      <td>1.278087</td>\n",
       "      <td>1.304617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wssx</th>\n",
       "      <td>0.021710</td>\n",
       "      <td>-0.046168</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>0.006476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wssy</th>\n",
       "      <td>0.010297</td>\n",
       "      <td>-0.074118</td>\n",
       "      <td>-0.008381</td>\n",
       "      <td>0.009542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wssz</th>\n",
       "      <td>0.079113</td>\n",
       "      <td>-0.036755</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.017247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>38.824947</td>\n",
       "      <td>-17.211851</td>\n",
       "      <td>15.181118</td>\n",
       "      <td>13.173093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>46.847960</td>\n",
       "      <td>-48.988758</td>\n",
       "      <td>-3.707316</td>\n",
       "      <td>24.354790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>82.896675</td>\n",
       "      <td>-5.897548</td>\n",
       "      <td>42.835144</td>\n",
       "      <td>18.339022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance</th>\n",
       "      <td>177.199800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.495740</td>\n",
       "      <td>45.188190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 max        min       mean        std\n",
       "label                                                \n",
       "pressure    3.398470  -7.650037   1.278087   1.304617\n",
       "wssx        0.021710  -0.046168  -0.002896   0.006476\n",
       "wssy        0.010297  -0.074118  -0.008381   0.009542\n",
       "wssz        0.079113  -0.036755   0.006116   0.017247\n",
       "x          38.824947 -17.211851  15.181118  13.173093\n",
       "y          46.847960 -48.988758  -3.707316  24.354790\n",
       "z          82.896675  -5.897548  42.835144  18.339022\n",
       "distance  177.199800   0.000000  67.495740  45.188190"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_information.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeff4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/home/yongqi/GNNField/poisson'\n",
    "# dataset = Poisson_2d_Dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49cf6805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = 400\n",
    "# test_size = 100\n",
    "# train_dataset = dataset[:train_size]\n",
    "# test_dataset = dataset[train_size:train_size+test_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d18ecc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Extracting output ranges from the data information for data normalization\n",
    "\n",
    "output_range = data_information.info.values[0].reshape(1, -1) # pressure!!!!!!!!!!!!!\n",
    "output_range = output_range.astype(np.float32)\n",
    "\n",
    "# Step 1: 提取 x, y, z 三行的数据（索引为 4, 5, 6）\n",
    "xyz_rows = data_information.info.values[4:7].astype(np.float32)\n",
    "\n",
    "# Step 2: 提取 mean 和 std 列（索引 2 和 3）\n",
    "xyz_mean = xyz_rows[:, 2]  # shape = (3,)\n",
    "xyz_std = xyz_rows[:, 3]   # shape = (3,)\n",
    "\n",
    "# Step 3: 计算 mean 和 std 的平均值\n",
    "shared_mean = np.mean(xyz_mean)\n",
    "shared_std = np.mean(xyz_std)\n",
    "\n",
    "# Step 4: 构造新的 mean/std 参数，用于 x/y/z 和其他维度（比如 distance）拼接\n",
    "# x/y/z 使用统一的 mean/std，distance 用原来的\n",
    "distance_row = data_information.info.values[7].astype(np.float32)  # index 7 是 distance\n",
    "\n",
    "# 构造 input normalization 参数，按列顺序排列\n",
    "# shape = (2, 4) → [mean_row, std_row]\n",
    "input_mean = np.array([shared_mean, shared_mean, shared_mean, distance_row[2]])\n",
    "input_std = np.array([shared_std, shared_std, shared_std, distance_row[3]])\n",
    "input_params = np.vstack([input_mean, input_std])  # shape = (2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb54eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_normalizer = Normalizer_ts(method='ms',params=input_range[:,2:].T)\n",
    "input_normalizer = Normalizer_ts(method='ms', params=input_params)\n",
    "output_normalizer = Normalizer_ts(method=\"ms\", params=output_range[:,2:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18617022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.loader import DataLoader\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size = 10)\n",
    "# test_loader = DataLoader(test_dataset, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57a87bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bench_Heat.heat_sampling_suk import HeatSamplingCluster\n",
    "from dataset import Aorta_3d_Dataset\n",
    "\n",
    "# Multiscale radius graph\n",
    "ratios = [1., 0.4, 0.1]\n",
    "radii = [0.042, 0.06, 0.8] # if artery_type == 'single' \n",
    "# else [0.022, 0.04, 0.1]\n",
    "\n",
    "trans = HeatSamplingCluster(ratios, radii)\n",
    "\n",
    "\n",
    "root = '/ehome/xinyi/Xinyi_GNN_aorta/data/toy_single'\n",
    "dataset = Aorta_3d_Dataset(root,'cpu', label='pressure', pre_transform=trans,input_normalizer=input_normalizer,output_normalizer=output_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cdca98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "total = len(dataset)\n",
    "train_size = int(0.9 * total)\n",
    "valid_size = int(0.1 * total)\n",
    "test_size  = total - train_size\n",
    "\n",
    "train_dataset, test_dataset= random_split(dataset, [train_size, test_size], generator=torch.Generator().manual_seed(0))\n",
    "_, valid_dataset = random_split(train_dataset, [train_size-valid_size, valid_size], generator=torch.Generator().manual_seed(1))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 4, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 1)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b3cf86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGN (232441 trainable parameters)\n"
     ]
    }
   ],
   "source": [
    "from Bench_Heat.single_scale.gnn_model import MGN\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "model = MGN()\n",
    "model.to(device)\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr,weight_decay=0.001)\n",
    "schedule = ExponentialLR(optimizer,.999)\n",
    "\n",
    "optim_para = {\n",
    "            'epoch': 0,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':1,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59c2fca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [10:33<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from train import train, valid\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ✅ checkpoint 路径\n",
    "ckpt_dir = 'checkpoints_toy'\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "\n",
    "# ✅ 图像保存路径\n",
    "fig_dir = 'figures_toy'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "# ✅ 初始化日志\n",
    "train_epoch_error = []\n",
    "val_epoch_error = []\n",
    "test_epoch_error = []\n",
    "check_idx = []\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# ✅ 开始训练\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = train(model, device, train_loader, optimizer, criterion, scheduler=schedule)\n",
    "    train_epoch_error.append(train_loss)\n",
    "\n",
    "    if (epoch  % 100) == 0:\n",
    "        val_loss = valid(model, device, valid_loader, criterion)\n",
    "        test_loss = valid(model, device, test_loader, criterion)\n",
    "\n",
    "        val_epoch_error.append(val_loss)\n",
    "        test_epoch_error.append(test_loss)\n",
    "        check_idx.append(epoch)\n",
    "\n",
    "        # ✅ 保存 checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'test_loss': test_loss\n",
    "        }, os.path.join(ckpt_dir, f'checkpoint_epoch_{epoch}.pt'))\n",
    "\n",
    "        # ✅ 画图 1：训练损失\n",
    "        fig1, ax1 = plt.subplots(figsize=(8, 5))\n",
    "        ax1.plot(\n",
    "            range(len(train_epoch_error)),\n",
    "            torch.stack(train_epoch_error).detach().cpu().numpy(),\n",
    "            color='C0', label='Train Loss'\n",
    "        )\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.set_title('Train Loss Curve')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        fig1.tight_layout()\n",
    "        fig1.savefig(os.path.join(fig_dir, f\"train_loss_epoch_{epoch}.png\"))\n",
    "        plt.close(fig1)\n",
    "\n",
    "        # ✅ 画图 2：Val/Test 损失（每 100 epoch）\n",
    "        fig2, ax2 = plt.subplots(figsize=(8, 5))\n",
    "        ax2.plot(\n",
    "            check_idx,\n",
    "            torch.stack(val_epoch_error).detach().cpu().numpy(),\n",
    "            color='C1', label='Validation Loss'\n",
    "        )\n",
    "        ax2.plot(\n",
    "            check_idx,\n",
    "            torch.stack(test_epoch_error).detach().cpu().numpy(),\n",
    "            color='C2', label='Test Loss'\n",
    "        )\n",
    "        ax2.set_yscale('log')\n",
    "        ax2.set_title('Validation & Test Loss (every 100 epochs)')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.legend()\n",
    "        fig2.tight_layout()\n",
    "        fig2.savefig(os.path.join(fig_dir, f\"val_test_loss_epoch_{epoch}.png\"))\n",
    "        plt.close(fig2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d697192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, device, train_loader, optimizer, criterion, scheduler=None):\n",
    "#     report_loss = 0\n",
    "#     model.train()\n",
    "#     for i, batch in enumerate(train_loader):\n",
    "#         optimizer.zero_grad()\n",
    "#         batch = batch.to(device)\n",
    "#         label = batch.y\n",
    "#         output = model(batch)\n",
    "#         loss = criterion(output, label)  # masked optimisation\n",
    "#         report_loss += loss.item()\n",
    "#         loss.backward()\n",
    "#         # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0, error_if_nonfinite=True)\n",
    "#         optimizer.step()\n",
    "#         if scheduler != None:\n",
    "#             scheduler.step()\n",
    "            \n",
    "#     return report_loss/len(train_loader)\n",
    "\n",
    "# def valid(model, device, val_loader, criterion):\n",
    "#     model.eval()\n",
    "#     valid_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for _, batch in enumerate(val_loader):\n",
    "#             batch = batch.to(device)\n",
    "#             label = batch.y\n",
    "#             output = model(batch)\n",
    "#             loss = criterion(output, label)\n",
    "#             valid_loss += loss.item()\n",
    "\n",
    "#     return valid_loss/len(val_loader)\n",
    "\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# import matplotlib.pyplot as plt\n",
    "# #start training \n",
    "# train_epoch_error = []\n",
    "# val_epoch_error = []\n",
    "# test_error = []\n",
    "# check_idx = []\n",
    "# epochs = 1000\n",
    "\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "#     train_epoch_error.append(train(model, device, train_loader, optimizer,criterion))\n",
    "#     test_error.append(valid(model, device, test_loader,criterion))\n",
    "#     check_idx.append(epoch+1)\n",
    "\n",
    "\n",
    "#     if (epoch+1)%500==0 and epoch != 0:    \n",
    "#         fig, ax = plt.subplots(figsize=(10,8))\n",
    "#         er1 = torch.tensor(train_epoch_error)\n",
    "#         er3 = torch.tensor(test_error)\n",
    "#         ax.plot(er1[1:],color = 'C0',linestyle='solid',linewidth=1,alpha=1,label='L_train')\n",
    "#         ax.plot(er3,color = 'C2',linestyle='solid',linewidth=1,alpha=1,label='L_test')\n",
    "#         ax.set_yscale('log')\n",
    "#         ax.set_title('train_loss_curve')\n",
    "#         ax.set_xlabel('epochs')\n",
    "#         ax.set_ylabel('loss')\n",
    "#         ax.legend()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b25e08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MP_Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mMP_Model\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Metrics\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Tabulate the evaluation metrics\u001b[39;00m\n\u001b[32m      6\u001b[39m     table = Metrics([test_loader]).statistics(model, torch.device(\u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m))\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'MP_Model'"
     ]
    }
   ],
   "source": [
    "from MP_Model.metrics import Metrics\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    Tabulate the evaluation metrics\n",
    "    table = Metrics([test_loader]).statistics(model, torch.device('cpu'))\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a9e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import pyvista as pv\n",
    "# import matplotlib.pyplot as plt\n",
    "# from os.path import join as osj\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def generate_output(\n",
    "#     model,\n",
    "#     device,\n",
    "#     output_loader,\n",
    "#     raw_mesh_path,\n",
    "#     tag,\n",
    "#     save_mesh_path,\n",
    "#     mesh_name=\"mesh\",\n",
    "#     # output_normalizer=None,\n",
    "# ):\n",
    "#     for _, batch in enumerate(tqdm(output_loader)):\n",
    "#         batch = batch.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             label = batch.y\n",
    "#             output = model(batch)\n",
    "#             idx = (batch.idx)[0]\n",
    "\n",
    "#             mesh = pv.read(osj(raw_mesh_path, \"single_artery{:04d}.vtu\".format(idx)))\n",
    "#             mesh.point_data[tag + \"_prediction\"] = output.detach().cpu()\n",
    "#             mesh.point_data[tag + \"_label\"] = label.detach().cpu()\n",
    "#             mesh.point_data[tag + \"_error\"] = (\n",
    "#                 mesh.point_data[tag + \"_prediction\"] - mesh.point_data[tag + \"_label\"]\n",
    "#             )\n",
    "#             mesh.save(osj(save_mesh_path, mesh_name + \"_{:d}.vtu\".format(idx)))\n",
    "\n",
    "\n",
    "# # generate_output(model,'cpu',train_loader,'aorta/raw','wss','results/meshes','mesh_wss_1',output_normalizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0087d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MP_Model.metrics import Metrics\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Tabulate the evaluation metrics\n",
    "    table = Metrics([test_loader]).statistics(model, torch.device('cpu'))\n",
    "    print(table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab-gatr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
